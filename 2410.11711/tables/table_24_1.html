<table id='7' style='font-size:14px'><tr><td>Environment</td><td>HalfCheetah</td><td>Hopper</td><td>Pendulum</td></tr><tr><td>Update frequency</td><td>1000</td><td>1000</td><td>200</td></tr><tr><td>Learning starts</td><td>5000</td><td>5000</td><td>1000</td></tr><tr><td>LLM Learning starts</td><td>10000</td><td>10000</td><td>2000</td></tr><tr><td>LLM Learning frequency</td><td>256</td><td>256</td><td>16</td></tr><tr><td>Batch size</td><td>128</td><td>128</td><td>64</td></tr><tr><td>LLM Batch size (ï¿½%)</td><td>7(5%), 13(10%), 32(25%)</td><td>7(5%), 13(10%), 32(25%)</td><td>4(5%), 7(10%), 16(25%)</td></tr><tr><td>Total timesteps</td><td>1e6</td><td>1e6</td><td>1e4</td></tr><tr><td>Gamma Y</td><td>0.99</td><td>0.99</td><td>0.99</td></tr><tr><td>Max context length</td><td>500</td><td>500</td><td>198</td></tr><tr><td>Min context length</td><td>1</td><td>1</td><td>1</td></tr><tr><td>LLM sampling method</td><td>mode</td><td>mode</td><td>mode</td></tr><tr><td>LLM dynamics learner</td><td>vICL</td><td>vICL</td><td>vICL</td></tr></table>